In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs. 
A standard computer chip circuit can be seen as a digital network of activation functions that can be "ON" (1) or "OFF" (0), depending on input. 
This is similar to the behavior of the linear perceptron in neural networks. 
However, only nonlinear activation functions allow such networks to compute nontrivial problems using only a small number of nodes.
In artificial neural networks, this function is also called the transfer function.
